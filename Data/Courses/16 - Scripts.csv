 Today, we'll talk about another knowledge representation called scripts. Scripts allow us to make sense of discourses and stories and scenes. Scripts are the culmination of of frames and understanding and common sense reasoning these last few lessons. We'll take what we learned about frames and understanding and common sense reasoning to build superior scripts. We'll start by defining scripts, then we'll talk about the form and the content of scripts. Then we'll discuss how we can use scripts to generate expectations about discourses and stories that help us make sense of the world around us. Finally, we'll talk about the hierarchical nature of scripts. I think you'll enjoy this lesson.
 To motivate our discussion of scripts, let us continue with our metaphor of machines with whom we can talk in stories. Now the Watson program and the Siri program, normally they understand stories that are limited to one sentence. You can ask Watson a question, you can ask Siri a question, and those questions are one sentence questions. Similarly when Siri and Watson reply, they typically give their answers in one word or one sentence at most. The story plays a very important role in the life of quadrant division and we would expect AI agents that live among quadrant divisions also to be able to understand stories. And one of the common roles that story players that they enable more common sense reasoning. To see how stories enable common sense reasoning, consider two simple sentences. Imagine the first sentence was, Ali asked, do you think we'll have many customers in the next half hour? And the second sentence is, Sarah replied, go ahead and grab your lunch. So these are two sentences of a story. Does this story make sense to you?
 What do you think, David, does it make sense to you? >> So, to me this story does make sense. I can imagine it as a story where Ali and Sarah are co-workers and Sarah has some kind of authority over Ali. Ali is looking around the store and saying that there aren't that many customers right now, so maybe now is a good time take my lunch. But if there's about to be a rush of customers, then now is not a good time because leaves Sarah there by herself. So Ali asks Sarah, do you think there are going to be many customers in the next half-hour? Sarah knows that it's around lunch time and Sarah recalls maybe that Ali had commented about missing breakfast this morning. So, she can infer Ali's motivation behind asking if there's going to be many customers, and she says, kind of anticipates the question he really was asking and says, yeah go ahead and take your lunch. So, yeah, I can find a way for this story to make sense, even though it doesn't seem like a clear connection between the two sentences. >> That's good David. Clearly you have an active imagination. Notice how David introduced lots of inferences here which were not really part of the input. How did he do it? This is common sense reasoning. How did he infer that it's probably lunchtime and that Ali wants to have lunch or that Sarah has some kind of authority over Ali? We have come across stories like this earlier. Here is another example. Ashok wanted to become rich, he got a gun. Two sentences and you can, I'm sure, understand immediately what might be going on. You may surmise that Ashok, as a professor, is unlikely to become rich, even if he teaches this online Master's course. On the other hand, you may have some stereotypical story about how some people become rich. Well, there are banks, and robbing a bank may require guns. And so now you can relate Ashok getting a gun to trying to become rich. So you and I, as human beings, have little difficulty in understanding stories like this. You might be given two sentences like this and we can connect them, causally connect them, coherently connect them, even if sometimes we use very active imaginations to do so. How can we do this conjoining of sentences into a coherent story? Put another way, how can we make AI agent do it? What kind of knowledge should the AI agent have and what kind of inferences must it make in order to be able to connect these two sentences?
 >> That's a good story David. Now let's consider a different set of issues. Imagine that I told you a story. Bob went to a restaurant and sat down. But nobody came to serve him for quite awhile. Eventually, when someone did appear, he ordered a hamburger. The hamburger took a long time before it came. And when it did come, it was burned. Bob was not very happy. He didn't even finish the hamburger. Do you think Bob left a large tip? Well, I expect most of you would say no. He did not leave a large tip. If we had to wait for a long time. And if the food that came eve, eventually, was not of very high quality. You'd probably not even ask tip. But how did you come to that answer? Why did you expect, that in this particular case, Bob will not leave a large tip? Again, this connects to your notion of a story. It connects to your notion of a story, of what happens in a restaurant. Why do people leave tips? When do they leave them? To put it another way, stories help you make sense of the world. They help you [INAUDIBLE] expectations, even before [UNKNOWN]. They allow us to make connections between evens that otherwise might appear disparate. So in this lesson, we'll look at another structured knowledge representation called scripts. For representing stories or the kind that we are talking about. And we will see how this knowledge for presentation allows us to make sense of the world. And answer the kinds of questions that we are talking about.
 >> Notice I didn't need to tell David what coffee house, what time of day, what he was ordering, who the cashier was etc. He has a script for that scene. And he associates it when needed. It helps with different expectations like, the cashier's going to give me my total, my drink should be coming up soon. If those expectations are not met, he knows something has gone wrong and he needs to react. This is the power of script. It helps to generate expectations about scenes in the world.
 So what is a script? A script is a knowledge representation for capturing causally coherent set of events. Casually means that one event sets off another. So when David goes to the coffee house, as soon as he approaches the counter, the barista comes to him and says, what do you want? One event has set off the next one. Coherent means the links between these events make sense in the context of the world around us. So in David's script again, ordering coffee doesn't cause the barista to slap in the face. Because that would not be causally coherent in the context of the world. These events are referent to events in the world. Some events, like deciding or concluding, might be in the actor's mind, but for the most part these events are observable events.
 So the structured knowledge for a presentation called script has six parts to it. The first part is called entry conditions. These are the conditions necessary to execute the script. So, for a restaurant script, as an example, the entry condition might be that there is a customer who is hungry and the customer has some money. The result refers to the conditions that will become true, after the script has occurred, after it has taken place. So, for restaurant script, the result might be that the owner of some restaurant has more money, the customer has less money, and the customer is now pleased and is no longer hungry. So the third part of a script is our props. So the third part of script are called props. Props are the kind of objects that are involved in the execution of this script so in case of the restaurant script the props might include tables and menus and food items and so on. So the fourth part of a script is roles. These are the agents involved in the execution of the script. As an example in the restaurant script it might be a customer who goes to a restaurant, the owner of the restaurant, the waiter or the waitresses in the restaurant, and so on. The fifth element of a script is a track. Track are variations or subclasses of a particular script. So for example in case of the restaurant script we may have tracks for going to a coffee house, or going to a fast food restaurant, or to a fine dining house. And finally the sixth element of a script refers to scenes. Scenes are specific sequence of events that occur during the execution of the script. So in case of the restaurant script there might be a scene for entering a restaurant. And a scene for ordering food. And a third scene for accepting the food and so on. When you put all of the six elements together then you get a complete script. In the previous lesson we had taken the metaphor of a molecule as a knowledge representation. That is, knowledge representations that are not small or short or not atomic, but are molecule in nature, script is a big, large molecule.
 So here is a representation of the restaurant script. Here is the name of the script, restaurant, and the six elements that we talked about earlier. Track, props, roles, entry, result and scenes. So this particular track refers to formal dining. Here are the props, tables, menu, check, money, food and place. And for food and place we can use symbols. These symbols can be used as variables. So where I may different kinds of foods and different kinds of places in a restaurant. Here are the rules, so S is a customer, W is a waiter, C is a cook, M is a cashier, O is an owner and so on. The entry conditions are S is hungry, S as the member is a customer, S has money and those conditions are that S has less money. S is not hungry. S is pleased. But O has more money. And scenes, well, let's discuss them in the next slide. Here is a representation of scene one. We'll call it the entering scene. This particular scene consists of several events. So in the first frame, the customer S, S stands for the customer. Moves himself or herself. So S is moving himself or herself to some restaurant, some place P. And the second frame, the agent S, the customer Sees some table. So this frame, the customer S decides to, take an action. The particular action is, where this agent S this customer S moves. Customer S himself or herself to the table. So this is a walking action going on. Let us continue another set just a little bit longer. So now S is moving his own body into a sitting position. Here, the waiter sees the customer, and now the waiter moves himself to the customer. And now the waiter moves the menu, to the customer. And this completes a representation of the first scene of entering in a restaurant. One can imagine many more scenes. The next scene might be a way to customer orders food. The third thing might be the way the waiter brings food, and so on and so forth. And then the last thing is the customer pays the bill and then walks out. This is a stereotypical notion of a script. Your notion of a script, might be slightly different depending on what kinds of restaurants that you go to. In different cultures, the script for going to a restaurant might be quite different. The point here is that the script is capturing in a knowledge representation, what is known about the stereotypical situation of going to a restaurant of a particular kind.
 So so far we have talked about a journal script of going to a restaurant, or an abstract script for going to a restaurant. This is like a class. We can instantiate it. So let's do this same script instantiated with these values with the greatest variables. So, Salwa is not a customer. Lucas is the waiter. And so on. And this instantiation is an important aspect of intelligence. Let's go back to our intelligent agent. It might be that Salwa is really a robot. Now, how would a robot know what to do in a restaurant? How do we program a robot in such a way that it would know what actions to take in a particular situation? Well, suppose that, Salwa the robot, in its memory, had a number of scripts like this one? And when it entered a restaurant, it invoked the restaurant script, which told it exactly what kind of actions to take. We could also see how this script allows Salwa, the robot, to generate expectations, to guess what will happen even before it happens. There is one more thing worth noting here. Notice how we are composing scripts of these primitive actions here, the same primitive actions that occurred in the last lesson. So, these primitive actions are now providing the fundamental units of frames that compose together in some causally coherent sequence, make a script. This brings up another point. Notice how some knowledge structures are composed out of other knowledge structures. Earlier, we had frames for these primitive actions, gave them social knowledge structures. Now, we have scripts which are composed out of these framelike knowledge structures.
 With effort to expectation generation just a while back let's look into it more deeply. So when we actually interact with the world sometimes things do not happen the way we expect them to happen. And sometimes things happen that people are not expecting. But how do we know what to expect and what not to expect? So consider a situation like this. This is an instance of a script. In this particular case, I have gone to Olive Garden. And the waiter is Andrew. So I move to a table and I sit down at the table. And now Andrew sees me. So from my perspective, I am expecting Andrew to come to me and give me a menu. But supposing this never happens. I am sitting there waiting for Andrew, or someone else, to come, and no one comes. That's an expectation violation. So I know something has gone awry. The reason I know that is because I continued expectations using the scripts, expectations that are never fulfilled. Now consider an alternate situation. Instead of Andrew coming to my table and giving me a menu, Andrew comes to me and gives me a bill right away. Well I should think that I would be surprised by that. That was an unexpected event that occurred. Well several questions arise here. First, could this be the beginning of theory of surprise? In both cases, we were surprised. In one case where Andrew did not come and give a menu. In the second case, when Andrew came and gave a bill instead of giving the menu. On second notice, a surprise, it has two sides to it. One, when things do not happen the way we expect them to happen. And the other, when things happen the way in which we were not expecting them to happen. This example shows, that scripts not only tell us what to make sense of the world around us, they also tell us what to expect and what not to expect. And that's a powerful idea. >> So it seems like another example where this happens really strongly, that we encounter fairly frequently, is if you've ever seen a horror movie. One thing that horror movies really do really, really well is they lure you into expecting one thing to happen only to throw something completely different at you. So they lure you into kind of a false sense of security in expecting that nothing bad is going to happen in a particular scene, and then suddenly they throw a ghost at you from offscreen and it kind of startles you. And the reason it startles you is because it violates your expectations for what were going to happen next. >> David, that's a good point, that it happens in many different kinds of movies. So when I go and see a science fiction movie, or even a romance movie, I'm expecting certain things to happen. And sometimes I think a movie is really good if it is new and novel and different and it offers some surprising things. Notice that this could also be the beginning of a theory of creativity. In the last lesson we were talking about balance and humor. No we're talking about surprises. Some current theories of creativity say that a situation is creative if it is A, novel, B, if it is useful or valuable in some way, and C, if it is unexpected or surprising. Now, this begins to capture at least one of those three dimensions of unexpectedness or surprise, and that's an important part. We'll return to computational creativity at the end of this course, when we'll talk a lot more about these issues.
 Now, another part of the script was the track. And we really haven't talked a lot about track so far. So let's talk a little bit more about it. So here are four tracks with the restaurant script. That really [INAUDIBLE] to going to restaurant, four kinds. Here's a coffeehouse, fast food, casual dining, formal dining. You could add more if you wanted to. Now in restaurants of all kinds, some even so common. You have to go to a restaurant, you have to order some food. You eat that food. You pay the bill. And then you leave. That is common to all of them which is why all of them are part of the restaurant script. On the other hand what happens in a Coffeehouse is quite different from what happens in Formal Dining, which is quite different from what happens in a Fast Food restaurant. So you may have specific cracks that correspond to Coffeehouses and Fast Foods and so on. In effect, we are building a semantic hierarchy or script. Here is a script for going to a restaurant. Here is a script for going to a coffeehouse, going to fast food. And this can be tracks in the overall script. Of course, we can build a semantic hierarchy of something higher than this. We could think about going to, for social events and [INAUDIBLE] going to this restaurant becomes part of going to a social event of various kind. Okay now that we know something about the [UNKNOWN] representation called script, the next question becomes how many AI agent actually use these scripts? So imagine an AI agent that is hungry has some money and decides to do something about it. So it may go into its long term memory and find out the script that will be most useful for the current situation. This really becomes a classification problem. In long term memory a large number of scripts, and the agent is trying to classify the current situation into one of those scripts. Let us suppose the agent picks a restaurant script, and decides to execute it. As it enters the restaurant, the scene it observes in the restaurant matches the conditions of a fast food script. So it decides to invoke the fast food script. This way the robot may walk down the semantic hierarchy, first in working the restaurant script, then working the fast food script, and so on. Now a robot could have taken a different stance. A robot could have decided to do planning. Given some initial conditions, and cold conditions, a robot may have used the operative that is available to it, to generate a plan at one time. While the script is doing it, it is giving it a plan in a compiled form. The robot doesn't have to generate this plan at runtime. It is already available in memory in a pre stored form. This is very useful because one of the central conundrums that we have been talking about is, how is it possible that AI agents can't address computationally complex problems with limited resources in near real time? In a complex dynamic world, planning can take a lot of time. But if I already have the store plans, then in working the script and executing it is much faster.
 So, we have talked a lot about how the notion of scripts is connected to many of the topics that we have discussed earlier in this course. So, let's do an exercise together. Which of the following topics might help an agent learn a script? Please check all that apply here.
 Which ones did you think, David, and why? >> So for learning a script, I said that five of the things we've talked about so far would really help an agent learn a script. So we've seen in the past that semantic networks and frames are representationally equivalent. We saw that when we put the raven's progressive matrices problems in terms of first semantic networks and then converted them to frames. Frames, as we've seen, are very useful for storing the type of information necessary to construct a thorough script. And if semantic networks are representationally equivalent, then we can also imagine a script composed of semantic networks instead. To skip the middle couple for a second, I can imagine incremental concept learning to be very important to learning scripts. We can an imagine an AI agent acting in the world and encountering multiple events everyday, and even to start to kind of develop a categorization scheme for those different experiences. So for example, that agent might learn that if I'm developing a script for fast food, whether or not I see a McDonald's logo or a Wendy's logo when I walk in, is not necessarily important to which script I run. But whether or not I see a counter with cashiers behind it or a hostess waiting to see me, is important. So that way, an agent can use incremental concept learning to learn the difference, for example, a fast food script and a fine dining script. So Ashok discussed before, planning happens when an agent has an initial state and a goal state and figures out how to navigate between the two. Once they figured out that plan for navigating between that initial state and that goal state, that then becomes a script that could be transferred to a new similar situation without having to completely re-plan the route from scratch. And finally common sense reasoning helps the agent out because it gives the agent a kind of a language within which to learn the script in the first place. It can learn a script within this language of primitive actions that it understands and then can use those to make sense of new and novel situations. Production systems and learning by recording cases don't really apply as much to scripts because they both involve representations at a very different level of abstraction, at a very low level of abstraction. With learning by recording cases, we tend to stick with the cases, whereas scripts we have an abstraction over them. And production systems are more like atoms of knowledge representation instead of molecules or compounds like we deal with with scripts. >> That's good, David. I may add, one of the things regarding the semantic networks. Recall that when we discussed semantic networks, we had considered how we could use semantic networks to interpret stories. We'll use this same example. Ashok wanted to become rich. He got a gun. And we said that inside a semantic network the notes that correspond to Ashok wanted rich and gun get activated. And the activation spread from there and there's a path that formed a spare semantic network that path is the interpretation of this particular story. In a sense a script is that part. >> Of course if you think you see a connection between production systems or learning by recording cases and scripts that I haven't seen. Or if you think the connection between the other topics and scripts isn't quite as close as I've described, feel free to head over to our forums and we'll discuss it there.
 Okay, let us do one more exercise together. This predicate exercise has to do with using a script rather than learning a script. Which of these topics that we have discussed earlier apply to an agent using a script? Check all that may apply.
 David, which of these topics do you think are applied to using a script? >> So I chose four of the seven as applied to using a script. So for problem reduction, we saw earlier that the script breaks down the overall scene into smaller scenes, and even further into smaller actions. What that means is that when we're executing the script, and it kind of gets caught somewhere we can break it down and see exactly where the script got caught. So we can see exactly where an expectation was violated. Classification we actually already discussed because classification can help us identify which script to execute in a given situation based on what we see. So if we walk into a restaurant and see a hostess for example we can classify that as a specific kind of restaurant and launch the script that goes along with it. Although it would take a bigger jump, I can also imagine putting a script in terms of formal logic. Especially because we discussed before, that a script can be considered a plan that has already been executed once, and can be transferred to new situations. So if we're discussing plans in the form of formal logic, we may also be able to put scripts in those same kind of terms. In terms of what they're asserting is true for a given state of the script. So if we could put plans in the form of formal logic, we can also imagine rewriting our script in the form of formal logic. That would give us a script in terms of what different elements of the script assert about the state of the world at different points of the script's execution. Finally, we can also see understanding applying pretty directly to scripts because it helps us disambiguate similar events in different situations. So to go with Ashok's example about receiving the bill right when you sit down at the table, understanding talks about how we can disambiguate that event based on what else has happened before and after. I didn't see the other three as being as applicable to scripts for a couple different reasons. For Generate & Test and Means-Ends Analysis, these are problem solving methods. And as we talked about with planning in the previous exercise, scripts are often used when we already have a solution and we simply need to execute it. Case-Based Reasoning keeps things at the level of individual cases that can be adapted to our current problem. Where as scripts serve as an abstraction over a number of cases. So I don't really see case-based reasoning applying as much here either. >> This is good, David. Thank you for sharing this. Note that Generate and & Test, and Case-Based Reasoning might be able to have the ability to use scripts after all. So one can imagine a situation where there are a large number of scripts available and the robot has to decide which of the scripts should I use for a particular situation. And may not be able to classify the situation dashed into scripts and with that case the robot will pick a script, generate it, try it out, see if it works, if it does not pick another one. Also Case-Based Reasoning is currently the application of scripts in the sense that both Case-Based Reasoning and script-based reasoning are extremely memory intensive. What both of them are saying is that memory often supplies most of the answer. Like we said earlier when we were discussing Case-Based Reasoning, we don't think as much as we think we do. Most of the time memory gives us the answer. The difference, of course, like David pointed out is, that cases defer to instances whereas scripts are abstractions of the instances.
 So how would scripts help inform the design of an agent to solve Raven's progressive matrices? Remember, scripts are ways of making sense of complex events in the world and we can certainly consider individual Raven's matrices to be complex situations. You thus might have a script for different broad categories of Raven's problems. If this was your approach, what would your entry conditions be for each script? What would the tracks be? What would the scenes be? Where are these scripts going to come from? Are you going to tell the agent what script it should use or will it learn a script from prior problems? If the agent succeeds using the script that you give it, who is intelligent? You or your agent?
 So today we've talked about scripts, a complex way of understanding stories in the natural world. Stories aren't just narratives, though. Painting, songs, buildings are all stories of different kinds. Stories are around us every single day. We started off by defining scripts. Scripts are causally coherent series of events. They give a prototype for what to expect in certain situations. The form of the general script shows us the form of the overall prototype for the situation. A specific instantiation of the script then specifies the content. Scripts can have different tracks as well. At a high level, any kind of restaurant involves entering, ordering, paying, and leaving. More narrowly though, fast food and drive through restaurants involve different scripts from casual or formal dining. This concludes our unit on common sense reasoning, but note that some of what we cover in the future will be applicable to learning, differentiating, and refining scripts.
 Scripts are strongly connected to current theories of human cognition. In fact one recent theory says that brain is a predictable machine. We do very quick bottom up processing followed by mostly top down processing with general expectations of the world. Then we act on those expectations. This idea in fact is so strong, that when it fails it leads to amusement, or surprise, or anger. If I violate the expectations of your script, you might find it funny or surprising or you might be upset about it. An interesting and open question is, whether we carry the scripts in our hear or do we generate them at run time? Scripts are also current with the notion of mental models. You and I have mental models, or scripts. Not just about social situations like going to a restaurant, going to a movie, but also about how the computer program works, how the economy works, how the car engine works, your physical, social, economic works. Note that scripts can be culture specific. In the U.S. for example, going to a restaurant typically involves leaving a tip. But in many countries, this is not the case. In fact in some countries, tipping is considered insulting. So scripts presumably evolved through cultural interaction over long periods of time. But once there, they're a very powerful source of knowledge.
 Please write down what you learned in this lesson.
 Great. Thank you so much for your feedback.
