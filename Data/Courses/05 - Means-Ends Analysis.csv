 Today we will discuss two other very general AR methods of problem solving called means end analysis and problem reduction. Like [INAUDIBLE] these two methods, means analysis and problem reduction, are really useful for very well-formed problems. Not all problems are well-formed. But some problems are. And then these methods are very useful. These three methods, generate and test, means-ends analysis, form reduction, together with semantic networks as a knowledge representation, form the basic unit of all fundamental topics in this course. We'll begin with the notion of state spaces. Then talk about means-end analysis. Then we'll illustrate means-end analysis as a matter for solving problems and then we'll move onto the method of problem reduction.
 To understand a method of means and analysis. Let us look at this blocks word problem. This is a very famous problem in AI. It has occurred again and again. And almost every textbook in AI has this problem. You're given a table on which there are three blocks. And A is on table, B is on table, and C is on A. This is the initial state. And you want to move these blocks, to the gold state. On this configuration, so that C is on table, B is on C and A is on B. The problem looks very simple listen, doesn't it? Let's introduce a couple of constraints. You may move only one block at a time, so you can't pick both A and B together. And second, you may only move a block that has nothing on top of it. So, you cannot move block A in this configuration, because it has C on top of it. Let us also suppose that we're given some operators in this world. These operators essentially move some object to some location. For example, we could move C to the table, or C onto B, or C onto A. Not all the operators may be applicable in the current state. C is already on A, but in principle, all these, all of these operators are available. Given these operators, and this initial state and this goal state, write a sequence of operations that will move the blocks from the initial state to the goal state.
 >> That's a good answer, David, that's a correct answer. Now the question becomes how can we make in AI agent that will come up with the similar sequence of operations? In particular, how does the matter of means-end analysis work on this problem and come up with a particular sequence of operations?
 So, we can imagine problem solving as occurring in a state space. Here is the initial state, here is the goal state. And the state space consists of all of the states that could be potentially produced from the initial state by iterative application of the various operators in this micro world. I want to come up with a path in the state space, takes me from initial state to the goal state. There is one path, this is not the only path, but this is one path to go from the initial state to the goal state. The question then becomes, how might an AI agent derive this path that may take it from the initial state to the goal state. Let us see how this notion of path finding applies to our blocks world problem. >From the initial state, here it is one path of going to the goal state. First, we put C on the table. Then we put B on top C. And then we put A on top of B. Which is exactly the answer that David had given. This is one sequence, one path from the initial state to the goal state. The question then becomes, how does AI method know what operation to select in a given state? Consider this state, for example. There are several operations possible here. One could put C on top of B or B on top of A. How does the AI agent know which operation to select at this particular state?
 One way of thinking about this is to talk in terms of differences. This chart illustrates the differences between different states and the goal state. So, for example, if the current state was this one then this red line illustrates the difference from the goal state. So we should pick an operator that will help reduce the difference between the current state and the goal state. So the reduction between the difference with the current state and the goal state is the end. The application of the operator is the means. That's why it's called the means-ends analysis. At any given state, I'm going to pick an operator that will help you deduce the difference between the current state and the goal state. Note in a way this problem is similar to the problem of part finding in robotics, where we have to design a robot that could go from one point to another point in some navigation space. >From my office to your office, for example, if all our offices were in the same building. There too we would use the notion of distances between offices. Here we using the notion of distance in a metaphorical sense, in a figurative sense, not in a physical sense. So I'll sometimes use the word difference instead of distance but it's the same idea. We are trying to deduce the distance or the difference but in an abstract space. So going back to an example of going from this initial state to this goal state. I can look at initial state and see that there are three differences between the initial state and the goal state. First, A is on table here, but A should be on B. B is on table here, but B should be on C. And third, C is on top of A here, the C should be on top, on table there. So three differences. Here the number of operations are available to us. Nine operations in particular. Let us do a means-end analysis. We can apply an operator that would put C on table. In which case the difference between the new state and the goal state will be two. We could apply an operator that will put C on top of B, in that case the difference between the current state and the goal state will still be three. Or we can apply the operator putting B on top of C, in which case the distance between the current state and the goal state will be 2. Notice that the notion of reducing differences now leads to two possible choices. One could go with this state or with this one. Means-end analysis by itself does not help an AI agent decide between this course of action and that course of action. This is something that we will return to, both a little bit later in this lesson and even much more in detail when we come to planning in this course. For now, let us resume that we choose the top course of action just like they had done already there. So this chart illustrates the pot taken from the initial state to the goal state. And the important thing to notice here is that with each different move the distance between the current state and the goal state is decreasing, from three to two to one to zero. This is why means-end analysis comes up with this path because at each time it reduces a difference
 We can summarize the means-ends analysis method like this. Compare the current state and the goal state. Find the differences between them. For each difference, look at what operators might be applicable. Select that operator that gets you closest to the goal state from the current state. We did this for the blocks and worlds problem. We also did this with regards to the business problem. But throughout those states in regards to business problem, which we're not getting us close to the goal state. This is the means-ends analysis method in summary.
 To understand more deeply the properties of means and analysis, let us look at another, slightly more complicated example. In this example, there are four blocks instead of the three in the previous example. A, B, C, D. In the initial state, the blocks are arranged as shown here. The goal state is shown here on the right. The four blocks are arranged in a particular order. Now if you compare the configuration of blocks on the left with the configuration of blocks on the right, in the goal state, you can see there are three differences. First, A is on Table, where A is on B here. B is on C. That's not a difference. C is on Table. C is on D here, D's on B, D's on Table here. So there are three differences. So, this is a heuristic measure of the difference between the initial state and the goal state. Once again, we'll assume that the AI agent can move only one block at a time. Given the specification of the problem, what states are possible from the initial state? Please write down your answers in these boxes.
 >> That's good David.
 Okay now for each of these states that is possible from the initial state what are the differences as compared to the goal state? Please write down your answers in these boxes.
 What answers did you come up with David? >> So for the first one, if we put A up on D, we haven't accomplished any of the goals that we hadn't already accomplished. So our difference is still 3. Similarly, for putting D on A, our difference is also still 3, because then we haven't accomplished anything new. However, if we put D down on the table, we've accomplished one of the goals we hadn't accomplished before. So there, our difference is 2. >> Good, David. So, in each state, David is comparing the state with the goal state, and finding differences between them.
 Given these three choices which operation would means-end analysis choose?
 What was your answer David? >> So means-ends analysis always chooses the state that most reduces the distance to the goal state. In this case, that would be the third option, because it reduces the distance down to two. >> That's correct David.
 Given this current state, we can apply means ends analysis veritably. Now, if we apply means on some of those to this particular state, the number of choices here is very large, so I will not go through all of them here. But I'd like you to write down the number of possible next states. As well as, how many of those states reduce the difference to the goal? Which is given here.
 What answers did you come up with, David? >> So I counted out seven possible next states. We can put B on A, B on D, B on the table, A on B, A on D or D on B or D on A. So that's seven total operations. Of those, only one of them accomplishes a goal we hadn't already accomplished, and that's putting A up on B. >> That's good, David.
 So, the operation of putting A on B will bring us to this state. Given this state, we can have, again, apply a means of analysis. Again, I'm not sure that all these states here, but I'd like you to find out how many possible states are there and how many of those states reduce the difference to the goal described.
 >> That's right David and that means that means-ends analysis doesn't not always take us to what's the goal. Sometimes it can take us away from the goal. And sometimes means-end analysis can get caught in loops. Means-end analysis, like genetic and test, is an example of universal error methods. These universal error methods are applicalbe to very large classes of problems. However, they can rate few guarantees of success, and they're often very costly. They're costly in terms of computational efficiency. They neither provide any guarantees of computational efficiency, nor provide any guarantees of the optimality of the solution that they come up with. Their power lies in the fact that they can be applied to a very large class of problems. Later in this class, we'll discuss problem-solving methods, which are very specialized problem-solving methods. Those methods are applicable to a smaller class of problems. However, they are more tuned to those problems and often are more efficient and sometimes, also provide guarantees over the optimality of the solution. Although means-end analysis did not work very for this problem. It in fact works quite well for many other problems and therefore is an important AI method. Later in this class when we come to planning, we will look at more powerful specialized methods that can in fact address this class of problems quite well.
 So how do you use means ends analysis to solve Raven's Progressive Matrices? What exactly is our goal in this context? You might think of the goal in different ways. We might think of it as, the goal is to solve the problem or in a different sense we might think of the goal as the transform sum frame into another frame. And then trace back and find what the transformation was? In that context how would you then measure distance? We noticed that distance is important in doing means ends analysis because that helps us decide what to do next. Once you have a measure of how to actually measure distance to your goal what are the individual operators or moves that you can take to actually move closer to your goal and how would you weight them to be able to decide what to do at any given time. In addition, what are the overall strengths of using means and analysis as a problem solving approach in this context, and what are its limitations. Is it well suited for these problems, or are there perhaps other things that we can be doing that aren't necessarily under this topic that would actually make the problem even easier.
 Let us now turn to the third problem solving method under this topic called problem reduction. The method of problem reduction actually is quite intuitive. I'm sure you use it all the time. Given the hard complex problem, reduce it. Decompose it into multiple easier, smaller, simpler problems. Consider, for example, computer programming or software design that I'm sure many of you do all the time. Given a hard part of the address, you decompose it with a series of smaller problems. How do I read the input? How do I process it? How do I write the output? That itself is a decomposition. In fact, one of the fundamental roles that knowledge plays is it tells you how to decompose a hard problem into simpler problems. Then once you have solutions to this simpler smaller problems. You can think about how to compose the sub-solutions to the sub-problems into a solution of the problem as a whole. That's how problem reduction works.
 Let us start from where we left off when we finished [UNKNOWN] analysis. This was the current state, this was the goal state. As we saw from [UNKNOWN] analysis, achieving this goal state is not a very easy problem. However, we can think of this goal state as being composed of several sub goals, so D on top of table. C on top of D. B on top of C. A on top of B. Four sub goals here. Now, we can try to address this problem by looking at one sub goal at a time. Let us suppose that we have picked this sub goal, C on top of D. Give that sub goal, we can now start from this current state and try to achieve this sub goal. Now of course, one might ask the question, why did we pick the goal C over D, and not the goal, B over C, or the goal A over B? Well one reason is that, the difference between this state and that state had to do with C over D. But in general, problem reduction by itself does not tell us, what sub-goal to attack first. That is a problem, we'll address later when we come to planning. Well now the major point is, that we can decompose the goal into several subgoals, and attack one subgoal at a time. Now that we have C over D as a subgoal, we really don't carry about whether A is on B or B is on C. What we are focused on is the other two states, C on table, D on table, because those are the blocks that occur in the goal state. So let us now see how [INAUDIBLE] have been solved this sub problem [INAUDIBLE] goal C on D and D on Table.
 So given this is a current state, what successor states are possible if we were to apply means and analysis? Please fill in these boxes.
 David, how did you fill up these boxes? >> So there are three possible moves here. A on the table, A on D, or D on A. So up top I have A on D, moving A to D. In the middle I have moving D up to A, and on the bottom I have A on the table. >> That looks right, David.
 Let us now calculate the difference from each of the states to the goal state.
 >> So note that both the state at the top and this state at the bottom have a equal amount of difference compared to goal state. We could've chosen either state to go further. For now, we going to go with the one at the bottom. The reason of course is that if I put A on D that will get in the way of solving the rest of the problem. For now, let us go with this state. Later on we will see how an AI agent will decide that this is not a good path to take and this is the better path to take.
 So if we make the move that we had at the end of the last shot, we'll get this state. So now we need to go from this state to the goal state. Please write down what is the sequence of operators which might take us from the current state to the goal state.
 What sequence did you come up with, David? >> So from this state, there's seven possible moves we can make initially. Some of them are going to move us away from our goal state. So putting D on A or D on B are going to move us away from our goal state. To means and to analysis, the rest of the moves are relatively the same. Putting A on B doesn't get us closer, putting B on C doesn't get us closer, and putting B on D doesn't get us closer. However, we can see that we really need to get B out of the way of C to move it up here. Like Ashad mentioned, later on we'll talk about how an agent would decide that it needs to get B out of the way of C. But for right now, let's just go ahead and choose B on Table as the next move. Given that, we now see that of the next possible states, only one reduces our difference, and that's to put C up on D. >> That was the right answer, David. Thank you. You will note that we're leaving several questions unanswered for now, and that is fine. But you will also note that this round reduction helps us make progress towards solving the problem.
 So the application of the last move in the previous shot will bring us to this state. In this state the the sub-goal C over D has been achieved. Now that we've achieved the first sub-goal, we can worry about achieving the other sub-goals. The other sub-goals, recall, were B over C and A over B. Given this as the current state and this as the goal state. Please write down the sequence of operations that will take us from the current state to the goal state.
 >> That was correct, David. Now this particular problem might look very simple. Because for you and me as humans, going from this state to this state is almost trivial. But notice how many different questions arose in trying to analyze this problem. Clearly, you and I as humans must be addressing these issues. This kind of A.I anaylsis makes explicit what is usually tacit when humans solve this problem. And that is one of the powers of A.I.. Indeed we have left a lot of questions unanswered. But each unanswered question then requires an answer. Now we know that if you must develop methods that somehow will help to address those questions. Like genetic [x] tests and like [x] dialysis. Problem reduction is a universal method. It is applicable very large class of problems. Once again, problem reduction does not provide guarantee of successes.
 Now that we have discussed means and analysis in problem production, let's revisit one of the problems that we would encounter when we were talking about the Raven's test of intelligence. So imagine that this is A and this is B. We can think of this as an initial state and this as a goal state. We know that A has been transformed into B. Now we can think in terms of a sequence of operations, that will transform this initial state into the goal state. It is one sequence. Delete it out, then move the diamond out of the circle. Then expanded out. Let us now see, we can think of this as an outward or means of analysis because each move here, brings us a little closer to the goal state. The advantage of doing this analysis and coming up with a sequence of transformations that will take us from the initial state of goal state as that. We cannot in [INAUDIBLE] of applying the same set of transformations to the image free, let's do that. We'll apply one transformation at a time, so we'll apply delete. We delete the dot. Now we apply move to this state, and it can give rise to several states. We have shown two here. Both of these spheres fulfill the requirements of this move operation of taking the diamond outside the circle. And now for each of the states, we can apply the operation of expand. Here we are expanding the circle, here too we are expanding the circle, although with different amounts. Once again the question here is, what in the image A corresponds to what in image C? How do we know that the diamond inside here corresponds to the circle inside the triangle here? We'll discuss this in detail when we discuss analogical reasoning, but for now, here is a partial answer. Remember that we had a semantic network representation of the image A. And in that representation, we said that the diamond is inside the circle. Now, we also have a semantic network representation of image C. And that semantic network representation says that the circle is inside the triangle. But it's that inside relationship that hints that this circle must correspond to the diamond. Because here the diamond is inside and here the circle is inside. So note then, that their presentation allows us to answer several questions about similarity, about correspondence and when we have metals, like means and analysis then we can do a systematic analysis of this transformations, and try to transfer this set of transformations to the new problem. >> What's interesting is we can also see this as an example of problem reduction. We initially just had a big problem that we had to solve. But here, we've reduced it to three subgoals. Our first subgoal is to find the transformation between A and B. Our second subgoal, is to transfer that transformation to C and find some candidate states for D. And our third subgoal, would be to compare those candidate states for D to each of the choices in our problem. >> That's good analysis, David. Let's go one step further. This also has generated. We are generating solutions that we can then test against the various choices that were given to us. So in this particular problem, you can see means and analysis working, problem reduction working, and the Raven's test working. Often, solving the complex problem requires a combination of AI techniques. At one point, one might use problem reduction. At another point, one might use the Raven's test, and at a third point, one might use means and analysis. Notice also, that the one single knowledge representation of semantic network supports all three of these strategies. The coupling between the knowledge representation of semantic network, and any of these three strategies, problem reduction, means and analysis, and generating test is weak. Later on we'll come across methods in which knowledge and the problem solving method are closely coupled. The knowledge affords certain inferences, and inferences demand certain kinds of knowledge. This is why these methods are known as Weak Methods. Because the coupling between this universal method and the knowledge representation is weak.
 So how would you apply a problem reduction to Raven's Progressive Matrices? Before we actually talk about how our agents would do it, we can think about how we would do it. When we are solving a matrix, where do the smaller or easier problems that we are actually breaking it down into? How are we solving those smaller problems, and how are we then combining them into an answer to the problem as a whole? Once we know how we're doing it, how will your agent actually be able to do the same kind of reasoning process? How will it recognize when to split a problem in to smaller problems? How will it solve the smaller problems? And how will it then combine those in to an answer to the problem as whole? During this process think about, what exactly is it that makes these smaller problems easier for your agent to answer than just answering the problem as a whole? And how does that actually help you solve these problems better?
 So let's wrap up what we've talked about today. We started off today by talking about state spaces and we used this to frame our discussion of mean-ends analysis. Means-ends analysis is a very general purpose problem solving method, that allows us to look at our goal and try to continually move towards it. We then use means-ends analysis to try and address a couple of different kinds of problems. But when we did so, we hit an obstacle. To overcome that obstacle, we used problem reduction. We can use problem reduction in a lot of other problem solving contexts, but here we use it to specifically to overcome the obstacle we hit during means-ends analysis. Problem reduction occurs and we take a big hard problem and introduce it into smaller easier problems. By solving the smaller easier problems, we solve the big hard problem. Next time we're going to talk about production systems, which are the last part of the fundamental areas of our course. But if you're particularly interested in what we've talked about today, you may wish to jump forward to logic and planning. Those were built specifically on the types of the problems we talked about today. And in fact in planning, we'll see a more robust way of solving the kinds of obstacles that we hit, during our exercise with means and analysis earlier in this lesson.
 Let us examine the connection between methods like means ends analysis and problem reduction on one hand, and human cognition on the other. Methods like means ends analysis, problem reduction and even generate and test, are sometimes called weak methods. They are weak because they make only little use of knowledge. Later on, we'll look at strong methods that are knowledge intensive. That will demand a lot of knowledge. The good thing about those knowledge intensive methods is, that they will actually use knowledge about the world, to come up with good solutions in an efficient manner. On the other hand, those knowledge intensive methods require knowledge, which is not always available. So humans, when they are working in a domain, in a world at which they are experts, tend to use those knowledge intensive methods because they know a lot about the world. But of course, you and I constantly work in worlds, in domains in which we are not experts. When we're not an expert in our domain, a domain that might be unfamiliar to us, then we might well go with matters that are weak because they don't require a lot of knowledge.
 We're at the end of this lesson. Please summarize what you learned in this lesson, inside this box.
 And thank you for doing it.
